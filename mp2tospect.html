<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Full MP3 Spectrogram</title>
    <style>
        body {
            background-color: #111;
            color: #fff;
            font-family: sans-serif;
            text-align: center;
            padding: 20px;
        }
        canvas {
            background-color: black;
            display: block;
            margin: 20px auto;
            border: 1px solid #444;
        }
    </style>
</head>
<body>
    <h1>MP3 to Full Spectrogram</h1>
    <input type="file" id="audioInput" accept=".mp3">
    <canvas id="spectrogram" width="1000" height="256"></canvas>

    <script>
        const audioInput = document.getElementById('audioInput');
        const canvas = document.getElementById('spectrogram');
        const ctx = canvas.getContext('2d');

        // Utility function to map intensity to a color (e.g., HSL heatmap)
        function getColor(value) {
            return `hsl(${value}, 100%, 50%)`;
        }

        audioInput.addEventListener('change', async function () {
            const file = this.files[0];

            if (!file) {
                alert('Please select an MP3 file.');
                return;
            }

            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const arrayBuffer = await file.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

            const sampleRate = audioBuffer.sampleRate;
            const channelData = audioBuffer.getChannelData(0); // Use first channel only

            const fftSize = 512;
            const hopSize = fftSize / 2;
            const numBins = fftSize / 2;

            const canvasWidth = canvas.width;
            const canvasHeight = canvas.height;

            const totalSamples = channelData.length;
            const totalFrames = Math.floor((totalSamples - fftSize) / hopSize);

            // To fit it on canvas, we may need to sample fewer frames than exist
            const framesToDraw = Math.min(canvasWidth, totalFrames);
            const frameStep = Math.floor(totalFrames / framesToDraw);

            // Prepare FFT
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = fftSize;
            const fftBuffer = new Uint8Array(numBins);

            const offlineCtx = new OfflineAudioContext(1, fftSize, sampleRate);

            for (let i = 0; i < framesToDraw; i++) {
                const start = i * frameStep * hopSize;
                const segment = channelData.slice(start, start + fftSize);

                const audioBufferSegment = offlineCtx.createBuffer(1, fftSize, sampleRate);
                audioBufferSegment.copyToChannel(segment, 0);

                const source = offlineCtx.createBufferSource();
                source.buffer = audioBufferSegment;

                const analyserNode = offlineCtx.createAnalyser();
                analyserNode.fftSize = fftSize;

                source.connect(analyserNode);
                analyserNode.connect(offlineCtx.destination);
                source.start();

                // Manually compute FFT
                analyserNode.getByteFrequencyData(fftBuffer);

                for (let y = 0; y < numBins; y++) {
                    const value = fftBuffer[y];
                    ctx.fillStyle = getColor(value);
                    ctx.fillRect(i, canvasHeight - y, 1, 1);
                }
            }

            alert('Spectrogram rendered.');
        });
    </script>
</body>
</html>
